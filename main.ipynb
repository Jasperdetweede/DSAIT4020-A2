{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cae6b255",
   "metadata": {},
   "source": [
    "# **Initialization** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "250f29be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656d0b61",
   "metadata": {},
   "source": [
    "### Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cce58cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "RAW_DATA_FOLDER = 'raw_data'\n",
    "TARGET_FILE_PATH = 'unprocessed_data'\n",
    "\n",
    "# Flow Controls\n",
    "RELOAD_RAW_DATA = False\n",
    "DATA = 'depression'  # Options: 'depression', 'insomnia', 'electrical_circuit'\n",
    "\n",
    "# System variables\n",
    "STATE = 42\n",
    "TEST_SET_FRACTION = 0.20\n",
    "MISSING_VALUES_THRESHOLD = 0.50\n",
    "SAMPLES_ELECTRICAL_CIRCUIT = 5000\n",
    "VERBOSE = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeeb00e7",
   "metadata": {},
   "source": [
    "# **Data Preparation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3601f28b",
   "metadata": {},
   "source": [
    "### Merge raw data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be2998a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from raw_data_loader import load_raw_data\n",
    "\n",
    "if (RELOAD_RAW_DATA):\n",
    "    load_raw_data(RAW_DATA_FOLDER, TARGET_FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8460a91b",
   "metadata": {},
   "source": [
    "### Preprocessing and Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f59207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 142 columns with >50.0% missing values\n",
      "Shape after dropping high-missing columns: (3333, 109)\n",
      "Replaced 708 special code values with NaN\n",
      "Replaced 186 special code values with NaN\n",
      "Ordinal columns: 27\n",
      "Nominal columns: 3\n",
      "Binary columns: 2\n",
      "Numerical columns: 74\n",
      "Object columns (excluded): 3\n",
      "Total columns identified: 109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaspe\\Documents\\Github_projects\\DSAIT4020-A2\\venv\\Lib\\site-packages\\sklearn\\impute\\_base.py:641: UserWarning: Skipping features without any observed values: ['SLQ300' 'SLQ310' 'SLQ320' 'SLQ330']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jaspe\\Documents\\Github_projects\\DSAIT4020-A2\\venv\\Lib\\site-packages\\sklearn\\impute\\_base.py:641: UserWarning: Skipping features without any observed values: ['SLQ300' 'SLQ310' 'SLQ320' 'SLQ330']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jaspe\\Documents\\Github_projects\\DSAIT4020-A2\\venv\\Lib\\site-packages\\sklearn\\impute\\_base.py:641: UserWarning: Skipping features without any observed values: ['SLQ300' 'SLQ310' 'SLQ320' 'SLQ330']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from preprocessing_depression import clean_and_preprocess_depression_data\n",
    "from preprocessing_insomnia import clean_and_preprocess_insomnia_data\n",
    "from preprocessing_electrical_circuit import gen_and_preprocess_ec_data\n",
    "\n",
    "dataset = pd.read_csv(TARGET_FILE_PATH + '/depression_data.csv')\n",
    "\n",
    "if DATA == 'depression':\n",
    "    X_train, X_test, y_train, y_test, y_embed_train, y_embed_test = clean_and_preprocess_depression_data(dataset, RAW_DATA_FOLDER, TEST_SET_FRACTION, STATE, MISSING_VALUES_THRESHOLD)\n",
    "elif DATA == 'insomnia':\n",
    "    X_train, X_test, y_train, y_test, y_embed_train, y_embed_test = clean_and_preprocess_insomnia_data(dataset, RAW_DATA_FOLDER, TEST_SET_FRACTION, STATE, MISSING_VALUES_THRESHOLD)\n",
    "elif DATA == 'electrical_circuit':\n",
    "    ec_X_train, ec_X_test, ec_y_train, ec_y_test, ec_y_embed_train, ec_y_embed_test = gen_and_preprocess_ec_data(SAMPLES_ELECTRICAL_CIRCUIT, TEST_SET_FRACTION, STATE)\n",
    "else:\n",
    "    raise ValueError(\"Invalid dataset selected\")\n",
    "\n",
    "#TODO Fix issue with the time columns SLQ300/310/320/330 in depression and processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907be545",
   "metadata": {},
   "source": [
    "# **Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b23470a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from baseline_models import train_multitarget_baseline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3383a4b1",
   "metadata": {},
   "source": [
    "### Training Bayesian Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33a6ac8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " ######################################## GaussianNB Multitarget Regressor ########################################\n",
      "Train MSE per embedding: [25.79027903 10.5379538   1.81578158  1.41134113  1.6249625   3.31743174\n",
      "  2.22232223 12.61056106  7.51755176]\n",
      "Test MSE per embedding: [26.91007194 10.45683453  2.0263789   1.47601918  1.68465228  3.55275779\n",
      "  2.40167866 13.19064748  7.89208633]\n",
      "Average train MSE: 7.427576090942428\n",
      "Average test MSE: 7.7323474553690374\n"
     ]
    }
   ],
   "source": [
    "nb_model = GaussianNB()\n",
    "y_pred_nb, acc_nb = train_multitarget_baseline(\n",
    "                            model=nb_model,\n",
    "                            is_classifier=False,\n",
    "                            X_train=X_train,\n",
    "                            X_test=X_test,\n",
    "                            y_embed_train=y_embed_train,\n",
    "                            y_embed_test=y_embed_test,\n",
    "                            verbose=VERBOSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ac3cc7",
   "metadata": {},
   "source": [
    "### Training Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30e979e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter\n",
    "N_ESTIMATORS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbaeae85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " ######################################## RandomForestRegressor Multitarget Regressor ########################################\n",
      "Train MSE per embedding: [0.13215092 0.0942333  0.12918404 0.11008542 0.11006673 0.08917942\n",
      " 0.07950783 0.07936454 0.04251734]\n",
      "Test MSE per embedding: [0.67283453 0.5841699  0.82962218 0.70119448 0.7444193  0.65046775\n",
      " 0.6631548  0.50801535 0.25973645]\n",
      "Average train MSE: 0.09625439210587726\n",
      "Average test MSE: 0.623734972022382\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestRegressor(n_estimators=N_ESTIMATORS, random_state=STATE, n_jobs=-1)\n",
    "y_pred_rf, mse_rf = train_multitarget_baseline(\n",
    "                                    model=rf_model, \n",
    "                                    is_classifier=False, \n",
    "                                    X_train=X_train, \n",
    "                                    X_test=X_test, \n",
    "                                    y_embed_train=y_embed_train, \n",
    "                                    y_embed_test=y_embed_test,\n",
    "                                    verbose=VERBOSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3172fa83",
   "metadata": {},
   "source": [
    "### Training Logistic Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f84084e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "MAX_ITERATIONS = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3635769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " ######################################## LogisticRegression Multitarget Classifier ########################################\n",
      "Train accuracy per embedding: [0.53045305 0.56675668 0.43114311 0.43054305 0.49654965 0.55745575\n",
      " 0.5529553  0.62676268 0.70507051]\n",
      "Test accuracy per embedding: [0.44604317 0.51798561 0.35251799 0.382494   0.43645084 0.5323741\n",
      " 0.49280576 0.57913669 0.66906475]\n",
      "Average train accuracy: 0.5441877521085442\n",
      "Average test accuracy: 0.4898747668531841\n"
     ]
    }
   ],
   "source": [
    "log_model = LogisticRegression(max_iter=MAX_ITERATIONS, class_weight='balanced', random_state=STATE)\n",
    "y_pred_log, acc_log = train_multitarget_baseline(\n",
    "                            model=log_model,\n",
    "                            is_classifier=True,\n",
    "                            X_train=X_train,\n",
    "                            X_test=X_test,\n",
    "                            y_embed_train=y_embed_train,\n",
    "                            y_embed_test=y_embed_test,\n",
    "                            verbose=VERBOSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777438b4",
   "metadata": {},
   "source": [
    "### Train Split MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aebf6f8e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msplit_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_split_model\n\u001b[32m      3\u001b[39m torch.device(\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mtrain_split_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_embed_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_embed_test\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaspe\\Documents\\Github_projects\\DSAIT4020-A2\\split_model.py:71\u001b[39m, in \u001b[36mtrain_split_model\u001b[39m\u001b[34m(X_train, X_test, y_train, y_test, y_embed_train, y_embed_test, device)\u001b[39m\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtrain_split_model\u001b[39m( X_train, X_test, y_train, y_test, y_embed_train, y_embed_test, device=\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m ):\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m \tn_features, n_samples = \u001b[43mX_train\u001b[49m\u001b[43m.\u001b[49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m \tembedding_size, _ = y_embed_train.size()\n\u001b[32m     74\u001b[39m \tmodel = SplitModel( n_features=n_features, embedding_size=embedding_size )\n",
      "\u001b[31mTypeError\u001b[39m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "from split_model import train_split_model\n",
    "\n",
    "torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_split_model( X_train, X_test, y_train, y_test, y_embed_train, y_embed_test )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3fbefb",
   "metadata": {},
   "source": [
    "### Train Joint MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da297fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joint_model import train_joint_model\n",
    "\n",
    "train_joint_model( X_train, X_test, y_train, y_test, y_embed_train, y_embed_test )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

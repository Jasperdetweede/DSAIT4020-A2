{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cae6b255",
   "metadata": {},
   "source": [
    "# **Initialization** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "250f29be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656d0b61",
   "metadata": {},
   "source": [
    "### Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cce58cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "RAW_DATA_FOLDER = 'raw_data'\n",
    "TARGET_FILE_PATH = 'unprocessed_data'\n",
    "\n",
    "# Flow Controls\n",
    "RELOAD_RAW_DATA = False\n",
    "DO_SMOTE = True\n",
    "DATA = 'depression'  # Options: 'depression', 'insomnia', 'electrical_circuit'\n",
    "\n",
    "# System variables\n",
    "STATE = 42\n",
    "TEST_SET_FRACTION = 0.20\n",
    "MISSING_VALUES_THRESHOLD = 0.50\n",
    "SAMPLES_ELECTRICAL_CIRCUIT = 5000\n",
    "VERBOSE = True\n",
    "FLIP_LABEL_FRACTION = 0.03\n",
    "\n",
    "np.random.seed(STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeeb00e7",
   "metadata": {},
   "source": [
    "# **Data Preparation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3601f28b",
   "metadata": {},
   "source": [
    "### Merge raw data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be2998a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from raw_data_loader import load_raw_data\n",
    "\n",
    "if (RELOAD_RAW_DATA):\n",
    "    load_raw_data(RAW_DATA_FOLDER, TARGET_FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8460a91b",
   "metadata": {},
   "source": [
    "### Preprocessing and Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9f59207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 142 columns with >50.0% missing values\n",
      "Shape after dropping high-missing columns: (3333, 109)\n",
      "Replaced 708 special code values with NaN\n",
      "Replaced 186 special code values with NaN\n",
      "Ordinal columns: 27\n",
      "Nominal columns: 3\n",
      "Binary columns: 2\n",
      "Numerical columns: 74\n",
      "Object columns (excluded): 3\n",
      "Total columns identified: 109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaspe\\Documents\\Github_projects\\DSAIT4020-A2\\venv\\Lib\\site-packages\\sklearn\\impute\\_base.py:641: UserWarning: Skipping features without any observed values: ['SLQ300' 'SLQ310' 'SLQ320' 'SLQ330']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jaspe\\Documents\\Github_projects\\DSAIT4020-A2\\venv\\Lib\\site-packages\\sklearn\\impute\\_base.py:641: UserWarning: Skipping features without any observed values: ['SLQ300' 'SLQ310' 'SLQ320' 'SLQ330']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jaspe\\Documents\\Github_projects\\DSAIT4020-A2\\venv\\Lib\\site-packages\\sklearn\\impute\\_base.py:641: UserWarning: Skipping features without any observed values: ['SLQ300' 'SLQ310' 'SLQ320' 'SLQ330']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from preprocessing_depression import clean_and_preprocess_depression_data\n",
    "from preprocessing_insomnia import clean_and_preprocess_insomnia_data\n",
    "from preprocessing_electrical_circuit import gen_and_preprocess_ec_data\n",
    "\n",
    "if DATA == 'depression':\n",
    "    dataset = pd.read_csv(TARGET_FILE_PATH + '/depression_data.csv')\n",
    "    X_train, X_test, y_train, y_test, y_embed_train, y_embed_test = clean_and_preprocess_depression_data(dataset, RAW_DATA_FOLDER, TEST_SET_FRACTION, STATE, MISSING_VALUES_THRESHOLD)\n",
    "elif DATA == 'insomnia':\n",
    "    dataset = pd.read_csv(TARGET_FILE_PATH + '/insomnia_data.csv')\n",
    "    X_train, X_test, y_train, y_test, y_embed_train, y_embed_test = clean_and_preprocess_insomnia_data(dataset, RAW_DATA_FOLDER, TEST_SET_FRACTION, STATE, MISSING_VALUES_THRESHOLD)\n",
    "elif DATA == 'electrical_circuit':\n",
    "    X_train, X_test, y_train, y_test, y_embed_train, y_embed_test = gen_and_preprocess_ec_data(SAMPLES_ELECTRICAL_CIRCUIT, TEST_SET_FRACTION, STATE)\n",
    "    DO_SMOTE = False\n",
    "else:\n",
    "    raise ValueError(\"Invalid dataset selected\")\n",
    "\n",
    "#TODO Fix issue with the time columns SLQ300/310/320/330 in depression and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c24fb23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [DPQ010, DPQ020, DPQ030, DPQ040, DPQ050, DPQ060, DPQ070, DPQ080, DPQ090]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "if DATA == \"depression\":\n",
    "    invalid_row_mask = y_embed_train.isin([7, 9]).any(axis=1)\n",
    "    print(y_embed_train[invalid_row_mask])\n",
    "    assert len(y_embed_train[invalid_row_mask]) == 0, \"There are targets with a 'refused' or 'unknown' value\"\n",
    "\n",
    "if DATA == \"insomnia\":\n",
    "    invalid_row_mask = y_embed_train.isna().any(axis=1)\n",
    "    print(y_embed_train[invalid_row_mask])\n",
    "    assert len(y_embed_train[invalid_row_mask]) == 0, \"There are targets with a 'refused' or 'unknown' value\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f43add",
   "metadata": {},
   "source": [
    "### Data Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bad909f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_balancing import resample_training_data\n",
    "\n",
    "if DO_SMOTE:\n",
    "    X_train, y_train, y_embed_train = resample_training_data(X_train, y_train, y_embed_train, random_state=STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23d5ad2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution:\n",
      " {np.int64(0): np.int64(3117), np.int64(1): np.int64(3007)}\n",
      "\n",
      "Class ratio: 0.965\n"
     ]
    }
   ],
   "source": [
    "# Check class distribution\n",
    "classes, counts = np.unique(y_train, return_counts=True)\n",
    "print(\"Class Distribution:\\n\", dict(zip(classes, counts)))\n",
    "\n",
    "if len(classes) > 1:\n",
    "    class_ratio = counts[1] / counts[0]\n",
    "    print(f\"\\nClass ratio: {class_ratio:.3f}\")\n",
    "else:\n",
    "    print(\"\\nOnly one class present.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf1687a-66bf-4c13-ae9d-b9f729255aae",
   "metadata": {},
   "source": [
    "### Introduce Noise to label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e605cc0-c7df-46fa-aafc-72d22d688dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert FLIP_LABEL_FRACTION > 0.0 and FLIP_LABEL_FRACTION < 1.0, \"FLIP_LABEL_FRACTION should be beween 0.0 and 1.0\"\n",
    "\n",
    "# Randomly select indices to flip\n",
    "if FLIP_LABEL_FRACTION > 0.0:\n",
    "    num_to_flip = int(FLIP_LABEL_FRACTION * len(y_train))\n",
    "    flip_indices = np.random.choice(len(y_train), size=num_to_flip, replace=False)\n",
    "\n",
    "    # If y_train is a pandas Series, convert to int for safe arithmetic\n",
    "    if hasattr(y_train, 'iloc'):\n",
    "        y_train = y_train.astype(int)\n",
    "        y_train.iloc[flip_indices] = 1 - y_train.iloc[flip_indices]\n",
    "    else:  # numpy array\n",
    "        y_train[flip_indices] = 1 - y_train[flip_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649caa02-af7b-4ed1-8893-ed4192ddc29d",
   "metadata": {},
   "source": [
    "### Make everything a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47910799-d5c6-4eb2-b8d2-fe5b597640b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values if hasattr(X_train, \"values\") else np.array(X_train)\n",
    "X_test = X_test.values if hasattr(X_test, \"values\") else np.array(X_test)\n",
    "\n",
    "y_train = y_train.values.ravel() if hasattr(y_train, \"values\") else np.array(y_train).ravel()\n",
    "y_test = y_test.values.ravel() if hasattr(y_test, \"values\") else np.array(y_test).ravel()\n",
    "\n",
    "y_embed_train = y_embed_train.values if hasattr(y_embed_train, \"values\") else np.array(y_embed_train)\n",
    "y_embed_test = y_embed_test.values if hasattr(y_embed_test, \"values\") else np.array(y_embed_test)\n",
    "\n",
    "assert(isinstance(X_train, np.ndarray))\n",
    "assert(isinstance(X_test, np.ndarray))\n",
    "assert(isinstance(y_train, np.ndarray))\n",
    "assert(isinstance(y_test, np.ndarray))\n",
    "assert(isinstance(y_embed_train, np.ndarray))\n",
    "assert(isinstance(y_embed_test, np.ndarray))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907be545",
   "metadata": {},
   "source": [
    "# **Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b23470a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from baseline_models import train_multitarget_baseline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3383a4b1",
   "metadata": {},
   "source": [
    "### Training Bayesian Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33a6ac8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " ######################################## GaussianNB Multitarget Regressor ########################################\n",
      "Train MSE per embedding: [1.36871326 2.02400392 1.81433703 1.12736773 1.33785108 1.58458524\n",
      " 2.50391901 5.25065317 5.10418027]\n",
      "Test MSE per embedding: [1.82168675 3.3        1.94096386 1.52409639 1.78433735 2.41084337\n",
      " 3.28433735 6.38554217 5.83975904]\n",
      "Average train MSE: 2.4572900791058863\n",
      "Average test MSE: 3.143507362784471\n"
     ]
    }
   ],
   "source": [
    "nb_model = GaussianNB()\n",
    "y_pred_nb, acc_nb = train_multitarget_baseline(\n",
    "                            model=nb_model,\n",
    "                            is_classifier=False,\n",
    "                            X_train=X_train,\n",
    "                            X_test=X_test,\n",
    "                            y_embed_train=y_embed_train,\n",
    "                            y_embed_test=y_embed_test,\n",
    "                            verbose=VERBOSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ac3cc7",
   "metadata": {},
   "source": [
    "### Training Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30e979e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter\n",
    "N_ESTIMATORS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbaeae85",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestRegressor(n_estimators=N_ESTIMATORS, random_state=STATE, n_jobs=-1)\n",
    "y_pred_rf, mse_rf = train_multitarget_baseline(\n",
    "                                    model=rf_model, \n",
    "                                    is_classifier=False, \n",
    "                                    X_train=X_train, \n",
    "                                    X_test=X_test, \n",
    "                                    y_embed_train=y_embed_train, \n",
    "                                    y_embed_test=y_embed_test,\n",
    "                                    verbose=VERBOSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3172fa83",
   "metadata": {},
   "source": [
    "### Training Logistic Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84084e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "MAX_ITERATIONS = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3635769",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: np.int64(3)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m log_model = LogisticRegression(max_iter=MAX_ITERATIONS, class_weight=\u001b[33m'\u001b[39m\u001b[33mbalanced\u001b[39m\u001b[33m'\u001b[39m, random_state=STATE)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m y_pred_log, acc_log = \u001b[43mtrain_multitarget_baseline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlog_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mis_classifier\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m                            \u001b[49m\u001b[43my_embed_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_embed_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m                            \u001b[49m\u001b[43my_embed_test\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_embed_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mVERBOSE\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaspe\\Documents\\Github_projects\\DSAIT4020-A2\\baseline_models.py:22\u001b[39m, in \u001b[36mtrain_multitarget_baseline\u001b[39m\u001b[34m(model, is_classifier, X_train, X_test, y_embed_train, y_embed_test, verbose)\u001b[39m\n\u001b[32m     19\u001b[39m     model = MultiOutputRegressor(model)\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Fit\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_embed_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# Predict train and test\u001b[39;00m\n\u001b[32m     25\u001b[39m y_pred_train = model.predict(X_train)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaspe\\Documents\\Github_projects\\DSAIT4020-A2\\venv\\Lib\\site-packages\\sklearn\\multioutput.py:543\u001b[39m, in \u001b[36mMultiOutputClassifier.fit\u001b[39m\u001b[34m(self, X, Y, sample_weight, **fit_params)\u001b[39m\n\u001b[32m    517\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, Y, sample_weight=\u001b[38;5;28;01mNone\u001b[39;00m, **fit_params):\n\u001b[32m    518\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Fit the model to data matrix X and targets Y.\u001b[39;00m\n\u001b[32m    519\u001b[39m \n\u001b[32m    520\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    541\u001b[39m \u001b[33;03m        Returns a fitted instance.\u001b[39;00m\n\u001b[32m    542\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m543\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    544\u001b[39m     \u001b[38;5;28mself\u001b[39m.classes_ = [estimator.classes_ \u001b[38;5;28;01mfor\u001b[39;00m estimator \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.estimators_]\n\u001b[32m    545\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaspe\\Documents\\Github_projects\\DSAIT4020-A2\\venv\\Lib\\site-packages\\sklearn\\base.py:1336\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1329\u001b[39m     estimator._validate_params()\n\u001b[32m   1331\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1332\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1333\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1334\u001b[39m     )\n\u001b[32m   1335\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1336\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaspe\\Documents\\Github_projects\\DSAIT4020-A2\\venv\\Lib\\site-packages\\sklearn\\multioutput.py:274\u001b[39m, in \u001b[36m_MultiOutputEstimator.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, **fit_params)\u001b[39m\n\u001b[32m    271\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    272\u001b[39m         routed_params.estimator.fit[\u001b[33m\"\u001b[39m\u001b[33msample_weight\u001b[39m\u001b[33m\"\u001b[39m] = sample_weight\n\u001b[32m--> \u001b[39m\u001b[32m274\u001b[39m \u001b[38;5;28mself\u001b[39m.estimators_ = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    275\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    276\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\n\u001b[32m    277\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    279\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    281\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.estimators_[\u001b[32m0\u001b[39m], \u001b[33m\"\u001b[39m\u001b[33mn_features_in_\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    282\u001b[39m     \u001b[38;5;28mself\u001b[39m.n_features_in_ = \u001b[38;5;28mself\u001b[39m.estimators_[\u001b[32m0\u001b[39m].n_features_in_\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaspe\\Documents\\Github_projects\\DSAIT4020-A2\\venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:91\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     79\u001b[39m warning_filters = (\n\u001b[32m     80\u001b[39m     filters_func() \u001b[38;5;28;01mif\u001b[39;00m filters_func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m warnings.filters\n\u001b[32m     81\u001b[39m )\n\u001b[32m     83\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     84\u001b[39m     (\n\u001b[32m     85\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     89\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     90\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaspe\\Documents\\Github_projects\\DSAIT4020-A2\\venv\\Lib\\site-packages\\joblib\\parallel.py:1986\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1984\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1985\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1986\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1988\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1989\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1990\u001b[39m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1991\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1992\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1993\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaspe\\Documents\\Github_projects\\DSAIT4020-A2\\venv\\Lib\\site-packages\\joblib\\parallel.py:1914\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1912\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1913\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1915\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1916\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaspe\\Documents\\Github_projects\\DSAIT4020-A2\\venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:184\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    180\u001b[39m                 this_warning_filter_dict[special_key] = this_value.pattern\n\u001b[32m    182\u001b[39m         warnings.filterwarnings(**this_warning_filter_dict, append=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m184\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaspe\\Documents\\Github_projects\\DSAIT4020-A2\\venv\\Lib\\site-packages\\sklearn\\multioutput.py:63\u001b[39m, in \u001b[36m_fit_estimator\u001b[39m\u001b[34m(estimator, X, y, sample_weight, **fit_params)\u001b[39m\n\u001b[32m     61\u001b[39m     estimator.fit(X, y, sample_weight=sample_weight, **fit_params)\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m     \u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m estimator\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaspe\\Documents\\Github_projects\\DSAIT4020-A2\\venv\\Lib\\site-packages\\sklearn\\base.py:1336\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1329\u001b[39m     estimator._validate_params()\n\u001b[32m   1331\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1332\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1333\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1334\u001b[39m     )\n\u001b[32m   1335\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1336\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaspe\\Documents\\Github_projects\\DSAIT4020-A2\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1243\u001b[39m, in \u001b[36mLogisticRegression.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m   1240\u001b[39m     max_squared_sum = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1242\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_classes < \u001b[32m2\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1243\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1244\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThis solver needs samples of at least 2 classes\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1245\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m in the data, but the data contains only one\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1246\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m class: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m % \u001b[38;5;28mself\u001b[39m.classes_[\u001b[32m0\u001b[39m]\n\u001b[32m   1247\u001b[39m     )\n\u001b[32m   1249\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.warm_start:\n\u001b[32m   1250\u001b[39m     warm_start_coef = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcoef_\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[31mValueError\u001b[39m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: np.int64(3)"
     ]
    }
   ],
   "source": [
    "log_model = LogisticRegression(max_iter=MAX_ITERATIONS, class_weight='balanced', random_state=STATE)\n",
    "y_pred_log, acc_log = train_multitarget_baseline(\n",
    "                            model=log_model,\n",
    "                            is_classifier=True,\n",
    "                            X_train=X_train,\n",
    "                            X_test=X_test,\n",
    "                            y_embed_train=y_embed_train,\n",
    "                            y_embed_test=y_embed_test,\n",
    "                            verbose=VERBOSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7acb7b-dd16-4725-96fe-5ba08b7a4259",
   "metadata": {},
   "source": [
    "## Proposed MLPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a4020a-3be1-4625-9323-5a674670d6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from proposed_models import train_joint_model, train_split_model, train_deep_joint_model, train_deep_split_model\n",
    "\n",
    "DEVICE = \"cpu\"#torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "E_KEEP_RATE = 0.7\n",
    "l = 1\n",
    "if DATA == 'depression':\n",
    "    l = 1e-2\n",
    "elif DATA == 'insomnia':\n",
    "    l = 1e-2\n",
    "elif DATA == 'electrical_circuit':\n",
    "    l = 1\n",
    "\n",
    "EPOCHS = 100\n",
    "AUGMENT_EPOCHS = EPOCHS//2\n",
    "EARLY_STOP_EPOCHS = EPOCHS//5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a932baae-9847-409c-b512-8255f7be4e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using  cpu  for torch\n"
     ]
    }
   ],
   "source": [
    "# Sanity Checks\n",
    "print(\"Using \", DEVICE, \" for torch\")\n",
    "\n",
    "assert X_train.shape[0] >= 100 and y_train.shape[0] >= 100 and y_embed_train.shape[0] >= 100, \"Arrays must have at least 100 samples for the check.\"\n",
    "\n",
    "aligned = (len(X_train[:100]) == len(y_train[:100])) and (len(X_train[:100]) == len(y_embed_train[:100]))\n",
    "assert aligned, \"First 100 samples of X_train, y_train, and y_embed_train are not aligned.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777438b4",
   "metadata": {},
   "source": [
    "### Train Joint MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebf6f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\t#####---------------------------------------------\t[10.0%]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrain_joint_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_embed_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_embed_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m                    \u001b[49m\u001b[43me_kept_ratio\u001b[49m\u001b[43m=\u001b[49m\u001b[43mE_KEEP_RATE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m                    \u001b[49m\u001b[43ml\u001b[49m\u001b[43m=\u001b[49m\u001b[43ml\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m                    \u001b[49m\u001b[43maugment_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mAUGMENT_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mearly_stop_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEARLY_STOP_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDEVICE\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m                  \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaspe\\Documents\\Github_projects\\DSAIT4020-A2\\proposed_models.py:59\u001b[39m, in \u001b[36mtrain_joint_model\u001b[39m\u001b[34m(X_train, X_test, y_train, y_test, e_train, e_test, e_kept_ratio, l, epochs, augment_epochs, early_stop_epochs, device)\u001b[39m\n\u001b[32m     57\u001b[39m datasets, layer_sizes  = get_datasets_and_layer_sizes( X_train, X_test, y_train, y_test, e_train, e_test, e_kept_ratio )\n\u001b[32m     58\u001b[39m model = JointModel( n_features=layer_sizes[\u001b[33m\"\u001b[39m\u001b[33mn_in\u001b[39m\u001b[33m\"\u001b[39m], hidden_size=layer_sizes[\u001b[33m\"\u001b[39m\u001b[33mn_reg\u001b[39m\u001b[33m\"\u001b[39m], l=l, device=device )\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m \u001b[43mtrain_proposal_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatasets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mJoint\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43maugment_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stop_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mearly_stop_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaspe\\Documents\\Github_projects\\DSAIT4020-A2\\proposed_models.py:103\u001b[39m, in \u001b[36mtrain_proposal_model\u001b[39m\u001b[34m(datasets, model, title, batch_size, epochs, augment_epochs, early_stop_epochs, device)\u001b[39m\n\u001b[32m    100\u001b[39m dataloader_train_no_e = DataLoader( datasets[\u001b[33m\"\u001b[39m\u001b[33mtrain_no_e\u001b[39m\u001b[33m\"\u001b[39m], batch_size=batch_size, shuffle=\u001b[38;5;28;01mFalse\u001b[39;00m )\n\u001b[32m    101\u001b[39m dataloader_test = DataLoader( datasets[\u001b[33m\"\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m\"\u001b[39m], batch_size=batch_size, shuffle=\u001b[38;5;28;01mFalse\u001b[39;00m )\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_train_w_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stop_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mearly_stop_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    104\u001b[39m e_pred_test, y_pred_test = model.predict( dataloader_test )\n\u001b[32m    105\u001b[39m present_model_metrics( datasets[\u001b[33m\"\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m\"\u001b[39m].y, y_pred_test, datasets[\u001b[33m\"\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m\"\u001b[39m].embedding, e_pred_test, title=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtitle\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m MLP\u001b[39m\u001b[33m\"\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaspe\\Documents\\Github_projects\\DSAIT4020-A2\\base_model.py:80\u001b[39m, in \u001b[36mBaseModel.fit\u001b[39m\u001b[34m(self, dataloader, epochs, early_stop_epochs)\u001b[39m\n\u001b[32m     77\u001b[39m \t\tembedding = embedding.to(\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m     79\u001b[39m \te_pred, y_pred = \u001b[38;5;28mself\u001b[39m.forward(X, end_to_end=embedding \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m \tloss += \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     81\u001b[39m loss /= \u001b[38;5;28mlen\u001b[39m(dataloader)\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m early_stop_epochs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaspe\\Documents\\Github_projects\\DSAIT4020-A2\\shallow_models.py:22\u001b[39m, in \u001b[36mJointModel.backward\u001b[39m\u001b[34m(self, y_pred, y_true, e_pred, e_true)\u001b[39m\n\u001b[32m     20\u001b[39m \tloss += \u001b[38;5;28mself\u001b[39m.l * \u001b[38;5;28mself\u001b[39m.loss_reg( e_pred, e_true )\n\u001b[32m     21\u001b[39m \u001b[38;5;28mself\u001b[39m.optim.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[38;5;28mself\u001b[39m.optim.step()\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaspe\\Documents\\Github_projects\\DSAIT4020-A2\\venv\\Lib\\site-packages\\torch\\_tensor.py:581\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    571\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    572\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    573\u001b[39m         Tensor.backward,\n\u001b[32m    574\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    579\u001b[39m         inputs=inputs,\n\u001b[32m    580\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m581\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    582\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    583\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaspe\\Documents\\Github_projects\\DSAIT4020-A2\\venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    342\u001b[39m     retain_graph = create_graph\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaspe\\Documents\\Github_projects\\DSAIT4020-A2\\venv\\Lib\\site-packages\\torch\\autograd\\graph.py:825\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    823\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    824\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m825\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    826\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    827\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    828\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    829\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "train_joint_model( X_train, X_test, y_train, y_test, y_embed_train, y_embed_test,\n",
    "                    e_kept_ratio=E_KEEP_RATE,\n",
    "                    l=l,\n",
    "                    epochs=EPOCHS,\n",
    "                    augment_epochs=AUGMENT_EPOCHS,\n",
    "                    early_stop_epochs=EARLY_STOP_EPOCHS,\n",
    "                    device=DEVICE\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3fbefb",
   "metadata": {},
   "source": [
    "### Train Split MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da297fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\t###################################---------------\t[70.0% - DONE]\n",
      "\n",
      "================================================================================\n",
      "================================   Split MLP   ================================\n",
      "================================================================================\n",
      "Regression Results:\n",
      "MSE:\t0.9559118747711182\n",
      "\n",
      "\n",
      "Classification Results:\n",
      "F1 score: 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96       775\n",
      "           1       0.00      0.00      0.00        59\n",
      "\n",
      "    accuracy                           0.93       834\n",
      "   macro avg       0.46      0.50      0.48       834\n",
      "weighted avg       0.86      0.93      0.90       834\n",
      "\n",
      "Confusion matrix:\n",
      " [[775   0]\n",
      " [ 59   0]]\n",
      "Training:\t###-----------------------------------------------\t[6.0%]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.14/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/usr/lib/python3.14/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/usr/lib/python3.14/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\t##################################################\t[100.0%]\n",
      "\n",
      "================================================================================\n",
      "==========================   Split MLP (Augmented)   ==========================\n",
      "================================================================================\n",
      "Regression Results:\n",
      "MSE:\t0.9751307964324951\n",
      "\n",
      "\n",
      "Classification Results:\n",
      "F1 score: 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96       775\n",
      "           1       0.00      0.00      0.00        59\n",
      "\n",
      "    accuracy                           0.93       834\n",
      "   macro avg       0.46      0.50      0.48       834\n",
      "weighted avg       0.86      0.93      0.90       834\n",
      "\n",
      "Confusion matrix:\n",
      " [[775   0]\n",
      " [ 59   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.14/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/usr/lib/python3.14/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/usr/lib/python3.14/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "train_split_model( X_train, X_test, y_train, y_test, y_embed_train, y_embed_test,\n",
    "                    e_kept_ratio=E_KEEP_RATE,\n",
    "                    epochs=EPOCHS,\n",
    "                    augment_epochs=AUGMENT_EPOCHS,\n",
    "                    early_stop_epochs=EARLY_STOP_EPOCHS,\n",
    "                    device=DEVICE\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31cd9f3-7021-4891-8cad-f2e4a9385bc1",
   "metadata": {},
   "source": [
    "### Train Deep Joint Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d3f100-ec35-4495-9dbf-a8fa10722067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\t############--------------------------------------\t[25.0% - DONE]\n",
      "\n",
      "================================================================================\n",
      "==============================   Deep Joint MLP   ==============================\n",
      "================================================================================\n",
      "Regression Results:\n",
      "MSE:\t1.1690424680709839\n",
      "\n",
      "\n",
      "Classification Results:\n",
      "F1 score: 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96       775\n",
      "           1       0.00      0.00      0.00        59\n",
      "\n",
      "    accuracy                           0.93       834\n",
      "   macro avg       0.46      0.50      0.48       834\n",
      "weighted avg       0.86      0.93      0.90       834\n",
      "\n",
      "Confusion matrix:\n",
      " [[775   0]\n",
      " [ 59   0]]\n",
      "Training:\t###-----------------------------------------------\t[6.0%]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.14/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/usr/lib/python3.14/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/usr/lib/python3.14/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\t####################------------------------------\t[40.0% - DONE]\n",
      "\n",
      "================================================================================\n",
      "========================   Deep Joint MLP (Augmented)   ========================\n",
      "================================================================================\n",
      "Regression Results:\n",
      "MSE:\t1.1690424680709839\n",
      "\n",
      "\n",
      "Classification Results:\n",
      "F1 score: 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96       775\n",
      "           1       0.00      0.00      0.00        59\n",
      "\n",
      "    accuracy                           0.93       834\n",
      "   macro avg       0.46      0.50      0.48       834\n",
      "weighted avg       0.86      0.93      0.90       834\n",
      "\n",
      "Confusion matrix:\n",
      " [[775   0]\n",
      " [ 59   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.14/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/usr/lib/python3.14/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/usr/lib/python3.14/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "train_deep_joint_model( X_train, X_test, y_train, y_test, y_embed_train, y_embed_test,\n",
    "                        e_kept_ratio=E_KEEP_RATE,\n",
    "                        l=l,\n",
    "                        epochs=EPOCHS,\n",
    "                        augment_epochs=AUGMENT_EPOCHS,\n",
    "                        early_stop_epochs=EARLY_STOP_EPOCHS,\n",
    "                        device=DEVICE\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eae81c0-f941-48f9-9ee6-ab0b9837fdb8",
   "metadata": {},
   "source": [
    "### Train Deep Split Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9afe671-bc85-474e-a353-870b65329c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\t######################################------------\t[77.0% - DONE]\n",
      "\n",
      "================================================================================\n",
      "==============================   Deep Split MLP   ==============================\n",
      "================================================================================\n",
      "Regression Results:\n",
      "MSE:\t1.2037678956985474\n",
      "\n",
      "\n",
      "Classification Results:\n",
      "F1 score: 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96       775\n",
      "           1       0.00      0.00      0.00        59\n",
      "\n",
      "    accuracy                           0.93       834\n",
      "   macro avg       0.46      0.50      0.48       834\n",
      "weighted avg       0.86      0.93      0.90       834\n",
      "\n",
      "Confusion matrix:\n",
      " [[775   0]\n",
      " [ 59   0]]\n",
      "Training:\t#####---------------------------------------------\t[10.0%]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.14/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/usr/lib/python3.14/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/usr/lib/python3.14/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\t##################################################\t[100.0%]\n",
      "\n",
      "================================================================================\n",
      "========================   Deep Split MLP (Augmented)   ========================\n",
      "================================================================================\n",
      "Regression Results:\n",
      "MSE:\t1.2037678956985474\n",
      "\n",
      "\n",
      "Classification Results:\n",
      "F1 score: 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96       775\n",
      "           1       0.00      0.00      0.00        59\n",
      "\n",
      "    accuracy                           0.93       834\n",
      "   macro avg       0.46      0.50      0.48       834\n",
      "weighted avg       0.86      0.93      0.90       834\n",
      "\n",
      "Confusion matrix:\n",
      " [[775   0]\n",
      " [ 59   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.14/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/usr/lib/python3.14/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/usr/lib/python3.14/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "train_deep_split_model( X_train, X_test, y_train, y_test, y_embed_train, y_embed_test,\n",
    "                        e_kept_ratio=E_KEEP_RATE,\n",
    "                        epochs=EPOCHS,\n",
    "                        augment_epochs=AUGMENT_EPOCHS,\n",
    "                        early_stop_epochs=EARLY_STOP_EPOCHS,\n",
    "                        device=DEVICE\n",
    "                      )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

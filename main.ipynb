{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cae6b255",
   "metadata": {},
   "source": [
    "# **Initialization** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250f29be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656d0b61",
   "metadata": {},
   "source": [
    "### Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce58cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "RAW_DATA_FOLDER = 'raw_data'\n",
    "TARGET_FILE_PATH = 'unprocessed_data'\n",
    "\n",
    "# Flow Controls\n",
    "RELOAD_RAW_DATA = False\n",
    "DO_SMOTE = True\n",
    "DATA = 'depression'  # Options: 'depression', 'insomnia', 'electrical_circuit'\n",
    "\n",
    "# System variables\n",
    "STATE = 42\n",
    "TEST_SET_FRACTION = 0.20\n",
    "MISSING_VALUES_THRESHOLD = 0.50\n",
    "SAMPLES_ELECTRICAL_CIRCUIT = 5000\n",
    "VERBOSE = True\n",
    "FLIP_LABEL_FRACTION = 0.03\n",
    "\n",
    "np.random.seed(STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeeb00e7",
   "metadata": {},
   "source": [
    "# **Data Preparation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3601f28b",
   "metadata": {},
   "source": [
    "### Merge raw data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2998a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from raw_data_loader import load_raw_data\n",
    "\n",
    "if (RELOAD_RAW_DATA):\n",
    "    load_raw_data(RAW_DATA_FOLDER, TARGET_FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8460a91b",
   "metadata": {},
   "source": [
    "### Preprocessing and Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f59207",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing_depression import clean_and_preprocess_depression_data\n",
    "from preprocessing_insomnia import clean_and_preprocess_insomnia_data\n",
    "from preprocessing_electrical_circuit import gen_and_preprocess_ec_data\n",
    "\n",
    "if DATA == 'depression':\n",
    "    dataset = pd.read_csv(TARGET_FILE_PATH + '/depression_data.csv')\n",
    "    X_train, X_test, y_train, y_test, y_embed_train, y_embed_test = clean_and_preprocess_depression_data(dataset, RAW_DATA_FOLDER, TEST_SET_FRACTION, STATE, MISSING_VALUES_THRESHOLD)\n",
    "elif DATA == 'insomnia':\n",
    "    dataset = pd.read_csv(TARGET_FILE_PATH + '/insomnia_data.csv')\n",
    "    X_train, X_test, y_train, y_test, y_embed_train, y_embed_test = clean_and_preprocess_insomnia_data(dataset, RAW_DATA_FOLDER, TEST_SET_FRACTION, STATE, MISSING_VALUES_THRESHOLD)\n",
    "    DO_SMOTE = False\n",
    "elif DATA == 'electrical_circuit':\n",
    "    X_train, X_test, y_train, y_test, y_embed_train, y_embed_test = gen_and_preprocess_ec_data(SAMPLES_ELECTRICAL_CIRCUIT, TEST_SET_FRACTION, STATE)\n",
    "    DO_SMOTE = False\n",
    "else:\n",
    "    raise ValueError(\"Invalid dataset selected\")\n",
    "\n",
    "#TODO Fix issue with the time columns SLQ300/310/320/330 in depression and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c24fb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATA == \"depression\":\n",
    "    invalid_row_mask = y_embed_train.isin([7, 9]).any(axis=1)\n",
    "    print(y_embed_train[invalid_row_mask])\n",
    "    assert len(y_embed_train[invalid_row_mask]) == 0, \"There are targets with a 'refused' or 'unknown' value\"\n",
    "\n",
    "if DATA == \"insomnia\":\n",
    "    invalid_row_mask = y_embed_train.isna().any(axis=1)\n",
    "    print(y_embed_train[invalid_row_mask])\n",
    "    assert len(y_embed_train[invalid_row_mask]) == 0, \"There are targets with a 'refused' or 'unknown' value\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f43add",
   "metadata": {},
   "source": [
    "### Data Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bad909f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_balancing import resample_training_data\n",
    "\n",
    "if DO_SMOTE:\n",
    "    X_train, y_train, y_embed_train = resample_training_data(X_train, y_train, y_embed_train, random_state=STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d5ad2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check class distribution\n",
    "classes, counts = np.unique(y_train, return_counts=True)\n",
    "print(\"Class Distribution:\\n\", dict(zip(classes, counts)))\n",
    "\n",
    "if len(classes) > 1:\n",
    "    class_ratio = counts[1] / counts[0]\n",
    "    print(f\"\\nClass ratio: {class_ratio:.3f}\")\n",
    "else:\n",
    "    print(\"\\nOnly one class present.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf1687a-66bf-4c13-ae9d-b9f729255aae",
   "metadata": {},
   "source": [
    "### Introduce Noise to label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e605cc0-c7df-46fa-aafc-72d22d688dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert FLIP_LABEL_FRACTION > 0.0 and FLIP_LABEL_FRACTION < 1.0, \"FLIP_LABEL_FRACTION should be beween 0.0 and 1.0\"\n",
    "\n",
    "# Randomly select indices to flip\n",
    "if FLIP_LABEL_FRACTION > 0.0:\n",
    "    num_to_flip = int(FLIP_LABEL_FRACTION * len(y_train))\n",
    "    flip_indices = np.random.choice(len(y_train), size=num_to_flip, replace=False)\n",
    "\n",
    "    # If y_train is a pandas Series, convert to int for safe arithmetic\n",
    "    if hasattr(y_train, 'iloc'):\n",
    "        y_train = y_train.astype(int)\n",
    "        y_train.iloc[flip_indices] = 1 - y_train.iloc[flip_indices]\n",
    "    else:  # numpy array\n",
    "        y_train[flip_indices] = 1 - y_train[flip_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649caa02-af7b-4ed1-8893-ed4192ddc29d",
   "metadata": {},
   "source": [
    "### Make everything a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47910799-d5c6-4eb2-b8d2-fe5b597640b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values if hasattr(X_train, \"values\") else np.array(X_train)\n",
    "X_test = X_test.values if hasattr(X_test, \"values\") else np.array(X_test)\n",
    "\n",
    "y_train = y_train.values.ravel() if hasattr(y_train, \"values\") else np.array(y_train).ravel()\n",
    "y_test = y_test.values.ravel() if hasattr(y_test, \"values\") else np.array(y_test).ravel()\n",
    "\n",
    "y_embed_train = y_embed_train.values if hasattr(y_embed_train, \"values\") else np.array(y_embed_train)\n",
    "y_embed_test = y_embed_test.values if hasattr(y_embed_test, \"values\") else np.array(y_embed_test)\n",
    "\n",
    "assert(isinstance(X_train, np.ndarray))\n",
    "assert(isinstance(X_test, np.ndarray))\n",
    "assert(isinstance(y_train, np.ndarray))\n",
    "assert(isinstance(y_test, np.ndarray))\n",
    "assert(isinstance(y_embed_train, np.ndarray))\n",
    "assert(isinstance(y_embed_test, np.ndarray))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907be545",
   "metadata": {},
   "source": [
    "# **Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b23470a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from baseline_models import train_multitarget_baseline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3383a4b1",
   "metadata": {},
   "source": [
    "### Training Bayesian Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a6ac8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model = GaussianNB()\n",
    "y_pred_nb, acc_nb = train_multitarget_baseline(\n",
    "                            model=nb_model,\n",
    "                            is_classifier=False,\n",
    "                            X_train=X_train,\n",
    "                            X_test=X_test,\n",
    "                            y_embed_train=y_embed_train,\n",
    "                            y_embed_test=y_embed_test,\n",
    "                            verbose=VERBOSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ac3cc7",
   "metadata": {},
   "source": [
    "### Training Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e979e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter\n",
    "N_ESTIMATORS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbaeae85",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestRegressor(n_estimators=N_ESTIMATORS, random_state=STATE, n_jobs=-1)\n",
    "y_pred_rf, mse_rf = train_multitarget_baseline(\n",
    "                                    model=rf_model, \n",
    "                                    is_classifier=False, \n",
    "                                    X_train=X_train, \n",
    "                                    X_test=X_test, \n",
    "                                    y_embed_train=y_embed_train, \n",
    "                                    y_embed_test=y_embed_test,\n",
    "                                    verbose=VERBOSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3172fa83",
   "metadata": {},
   "source": [
    "### Training Logistic Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84084e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "MAX_ITERATIONS = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3635769",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model = LogisticRegression(max_iter=MAX_ITERATIONS, class_weight='balanced', random_state=STATE)\n",
    "y_pred_log, acc_log = train_multitarget_baseline(\n",
    "                            model=log_model,\n",
    "                            is_classifier=True,\n",
    "                            X_train=X_train,\n",
    "                            X_test=X_test,\n",
    "                            y_embed_train=y_embed_train,\n",
    "                            y_embed_test=y_embed_test,\n",
    "                            verbose=VERBOSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7acb7b-dd16-4725-96fe-5ba08b7a4259",
   "metadata": {},
   "source": [
    "## Proposed MLPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a4020a-3be1-4625-9323-5a674670d6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from proposed_models import train_joint_model, train_split_model, train_deep_joint_model, train_deep_split_model\n",
    "\n",
    "DEVICE = \"cpu\"#torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "E_KEEP_RATE = 0.7\n",
    "l = 1\n",
    "if DATA == 'depression':\n",
    "    l = 1e-2\n",
    "elif DATA == 'insomnia':\n",
    "    l = 1e-2\n",
    "elif DATA == 'electrical_circuit':\n",
    "    l = 1\n",
    "\n",
    "EPOCHS = 100\n",
    "AUGMENT_EPOCHS = EPOCHS//2\n",
    "EARLY_STOP_EPOCHS = EPOCHS//5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a932baae-9847-409c-b512-8255f7be4e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity Checks\n",
    "print(\"Using \", DEVICE, \" for torch\")\n",
    "\n",
    "assert X_train.shape[0] >= 100 and y_train.shape[0] >= 100 and y_embed_train.shape[0] >= 100, \"Arrays must have at least 100 samples for the check.\"\n",
    "\n",
    "aligned = (len(X_train[:100]) == len(y_train[:100])) and (len(X_train[:100]) == len(y_embed_train[:100]))\n",
    "assert aligned, \"First 100 samples of X_train, y_train, and y_embed_train are not aligned.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777438b4",
   "metadata": {},
   "source": [
    "### Train Joint MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebf6f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_joint_model( X_train, X_test, y_train, y_test, y_embed_train, y_embed_test,\n",
    "                    e_kept_ratio=E_KEEP_RATE,\n",
    "                    l=l,\n",
    "                    epochs=EPOCHS,\n",
    "                    augment_epochs=AUGMENT_EPOCHS,\n",
    "                    early_stop_epochs=EARLY_STOP_EPOCHS,\n",
    "                    device=DEVICE\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3fbefb",
   "metadata": {},
   "source": [
    "### Train Split MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da297fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split_model( X_train, X_test, y_train, y_test, y_embed_train, y_embed_test,\n",
    "                    e_kept_ratio=E_KEEP_RATE,\n",
    "                    epochs=EPOCHS,\n",
    "                    augment_epochs=AUGMENT_EPOCHS,\n",
    "                    early_stop_epochs=EARLY_STOP_EPOCHS,\n",
    "                    device=DEVICE\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31cd9f3-7021-4891-8cad-f2e4a9385bc1",
   "metadata": {},
   "source": [
    "### Train Deep Joint Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d3f100-ec35-4495-9dbf-a8fa10722067",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_deep_joint_model( X_train, X_test, y_train, y_test, y_embed_train, y_embed_test,\n",
    "                        e_kept_ratio=E_KEEP_RATE,\n",
    "                        l=l,\n",
    "                        epochs=EPOCHS,\n",
    "                        augment_epochs=AUGMENT_EPOCHS,\n",
    "                        early_stop_epochs=EARLY_STOP_EPOCHS,\n",
    "                        device=DEVICE\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eae81c0-f941-48f9-9ee6-ab0b9837fdb8",
   "metadata": {},
   "source": [
    "### Train Deep Split Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9afe671-bc85-474e-a353-870b65329c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_deep_split_model( X_train, X_test, y_train, y_test, y_embed_train, y_embed_test,\n",
    "                        e_kept_ratio=E_KEEP_RATE,\n",
    "                        epochs=EPOCHS,\n",
    "                        augment_epochs=AUGMENT_EPOCHS,\n",
    "                        early_stop_epochs=EARLY_STOP_EPOCHS,\n",
    "                        device=DEVICE\n",
    "                      )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

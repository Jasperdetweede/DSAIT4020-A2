{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cae6b255",
   "metadata": {},
   "source": [
    "# **Initialization** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "250f29be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656d0b61",
   "metadata": {},
   "source": [
    "### Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cce58cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "RAW_DATA_FOLDER = 'raw_data'\n",
    "TARGET_FILE_PATH = 'unprocessed_data'\n",
    "\n",
    "# Flow Controls\n",
    "RELOAD_RAW_DATA = False\n",
    "DO_SMOTE = True\n",
    "DATA = 'insomnia'  # Options: 'depression', 'insomnia', 'electrical_circuit'\n",
    "\n",
    "# System variables\n",
    "STATE = 42\n",
    "TEST_SET_FRACTION = 0.20\n",
    "MISSING_VALUES_THRESHOLD = 0.50\n",
    "SAMPLES_ELECTRICAL_CIRCUIT = 5000\n",
    "VERBOSE = True\n",
    "FLIP_LABEL_FRACTION = 0.03\n",
    "\n",
    "np.random.seed(STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeeb00e7",
   "metadata": {},
   "source": [
    "# **Data Preparation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3601f28b",
   "metadata": {},
   "source": [
    "### Merge raw data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be2998a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from raw_data_loader import load_raw_data\n",
    "\n",
    "if (RELOAD_RAW_DATA):\n",
    "    load_raw_data(RAW_DATA_FOLDER, TARGET_FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8460a91b",
   "metadata": {},
   "source": [
    "### Preprocessing and Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9f59207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2794\n",
      "1    1329\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaspe\\Documents\\Github_projects\\DSAIT4020-A2\\preprocessing_insomnia.py:704: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[\"approximate_freq_moderate_LTPA\"] = data[\"PAD790Q\"] * data[\"PAD790U\"].map(convert_frequency)\n",
      "c:\\Users\\jaspe\\Documents\\Github_projects\\DSAIT4020-A2\\preprocessing_insomnia.py:705: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[\"approximate_freq_vigorous_LTPA\"] = data[\"PAD810Q\"] * data[\"PAD810U\"].map(convert_frequency)\n",
      "c:\\Users\\jaspe\\Documents\\Github_projects\\DSAIT4020-A2\\preprocessing_insomnia.py:707: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[\"approximate_mins_moderate_LTPA\"] = data[\"approximate_freq_moderate_LTPA\"] * data[\"PAD800\"]\n",
      "c:\\Users\\jaspe\\Documents\\Github_projects\\DSAIT4020-A2\\preprocessing_insomnia.py:708: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[\"approximate_mins_vigorous_LTPA\"] = data[\"approximate_freq_vigorous_LTPA\"] * data[\"PAD820\"]\n",
      "c:\\Users\\jaspe\\Documents\\Github_projects\\DSAIT4020-A2\\preprocessing_insomnia.py:722: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[\"insulin_time\"] = data[\"DID060\"] * data[\"DIQ060U\"].map(convert_month_year)\n",
      "c:\\Users\\jaspe\\Documents\\Github_projects\\DSAIT4020-A2\\preprocessing_insomnia.py:746: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[\"FNQ520_fixed\"] = data[\"FNQ520\"].map(order_corrected)\n",
      "c:\\Users\\jaspe\\Documents\\Github_projects\\DSAIT4020-A2\\preprocessing_insomnia.py:747: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[\"FNQ540_fixed\"] = data[\"FNQ540\"].map(order_corrected)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaspe\\Documents\\Github_projects\\DSAIT4020-A2\\preprocessing_insomnia.py:704: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[\"approximate_freq_moderate_LTPA\"] = data[\"PAD790Q\"] * data[\"PAD790U\"].map(convert_frequency)\n",
      "c:\\Users\\jaspe\\Documents\\Github_projects\\DSAIT4020-A2\\preprocessing_insomnia.py:705: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[\"approximate_freq_vigorous_LTPA\"] = data[\"PAD810Q\"] * data[\"PAD810U\"].map(convert_frequency)\n",
      "c:\\Users\\jaspe\\Documents\\Github_projects\\DSAIT4020-A2\\preprocessing_insomnia.py:707: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[\"approximate_mins_moderate_LTPA\"] = data[\"approximate_freq_moderate_LTPA\"] * data[\"PAD800\"]\n",
      "c:\\Users\\jaspe\\Documents\\Github_projects\\DSAIT4020-A2\\preprocessing_insomnia.py:708: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[\"approximate_mins_vigorous_LTPA\"] = data[\"approximate_freq_vigorous_LTPA\"] * data[\"PAD820\"]\n",
      "c:\\Users\\jaspe\\Documents\\Github_projects\\DSAIT4020-A2\\preprocessing_insomnia.py:722: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[\"insulin_time\"] = data[\"DID060\"] * data[\"DIQ060U\"].map(convert_month_year)\n",
      "c:\\Users\\jaspe\\Documents\\Github_projects\\DSAIT4020-A2\\preprocessing_insomnia.py:746: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[\"FNQ520_fixed\"] = data[\"FNQ520\"].map(order_corrected)\n",
      "c:\\Users\\jaspe\\Documents\\Github_projects\\DSAIT4020-A2\\preprocessing_insomnia.py:747: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[\"FNQ540_fixed\"] = data[\"FNQ540\"].map(order_corrected)\n"
     ]
    }
   ],
   "source": [
    "from preprocessing_depression import clean_and_preprocess_depression_data\n",
    "from preprocessing_insomnia import clean_and_preprocess_insomnia_data\n",
    "from preprocessing_electrical_circuit import gen_and_preprocess_ec_data\n",
    "\n",
    "dataset = pd.read_csv(TARGET_FILE_PATH + '/depression_data.csv')\n",
    "\n",
    "if DATA == 'depression':\n",
    "    X_train, X_test, y_train, y_test, y_embed_train, y_embed_test = clean_and_preprocess_depression_data(dataset, RAW_DATA_FOLDER, TEST_SET_FRACTION, STATE, MISSING_VALUES_THRESHOLD)\n",
    "elif DATA == 'insomnia':\n",
    "    X_train, X_test, y_train, y_test, y_embed_train, y_embed_test = clean_and_preprocess_insomnia_data(dataset, RAW_DATA_FOLDER, TEST_SET_FRACTION, STATE, MISSING_VALUES_THRESHOLD)\n",
    "elif DATA == 'electrical_circuit':\n",
    "    X_train, X_test, y_train, y_test, y_embed_train, y_embed_test = gen_and_preprocess_ec_data(SAMPLES_ELECTRICAL_CIRCUIT, TEST_SET_FRACTION, STATE)\n",
    "    DO_SMOTE = False\n",
    "else:\n",
    "    raise ValueError(\"Invalid dataset selected\")\n",
    "\n",
    "#TODO Fix issue with the time columns SLQ300/310/320/330 in depression and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c24fb23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      SLQ300  SLQ310  SLD012  SLQ320  SLQ330  SLD013\n",
      "1247    60.0   570.0     8.0   600.0   600.0     NaN\n",
      "3399    60.0   330.0     4.0     NaN     NaN     2.0\n",
      "1902    60.0   300.0     4.0     NaN     NaN    14.0\n",
      "3500   360.0   750.0     6.0     NaN     NaN    14.0\n",
      "1748     NaN     NaN     NaN     NaN     NaN     NaN\n",
      "...      ...     ...     ...     ...     ...     ...\n",
      "4089  1260.0   240.0     7.0     NaN     NaN     NaN\n",
      "2880  1380.0   360.0     7.0     NaN     NaN     NaN\n",
      "3149     NaN     NaN     NaN     NaN     NaN     NaN\n",
      "469      NaN     NaN     2.0   240.0   540.0     5.0\n",
      "1181     NaN     NaN    14.0     0.0   840.0    14.0\n",
      "\n",
      "[84 rows x 6 columns]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "There are targets with a 'refused' or 'unknown' value",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m invalid_row_mask = y_embed_train.isna().any(axis=\u001b[32m1\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(y_embed_train[invalid_row_mask])\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_embed_train[invalid_row_mask]) == \u001b[32m0\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mThere are targets with a \u001b[39m\u001b[33m'\u001b[39m\u001b[33mrefused\u001b[39m\u001b[33m'\u001b[39m\u001b[33m or \u001b[39m\u001b[33m'\u001b[39m\u001b[33munknown\u001b[39m\u001b[33m'\u001b[39m\u001b[33m value\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mAssertionError\u001b[39m: There are targets with a 'refused' or 'unknown' value"
     ]
    }
   ],
   "source": [
    "if DATA == \"depression\":\n",
    "    invalid_row_mask = y_embed_train.isin([7, 9]).any(axis=1)\n",
    "    print(y_embed_train[invalid_row_mask])\n",
    "    assert len(y_embed_train[invalid_row_mask]) == 0, \"There are targets with a 'refused' or 'unknown' value\"\n",
    "\n",
    "if DATA == \"insomnia\":\n",
    "    invalid_row_mask = y_embed_train.isna().any(axis=1)\n",
    "    print(y_embed_train[invalid_row_mask])\n",
    "    assert len(y_embed_train[invalid_row_mask]) == 0, \"There are targets with a 'refused' or 'unknown' value\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f43add",
   "metadata": {},
   "source": [
    "### Data Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bad909f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_balancing import resample_training_data\n",
    "\n",
    "if DO_SMOTE:\n",
    "    X_train, y_train, y_embed_train = resample_training_data(X_train, y_train, y_embed_train, random_state=STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23d5ad2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution:\n",
      " {np.int64(0): np.int64(3104), np.int64(1): np.int64(3024)}\n",
      "\n",
      "Class ratio: 0.974\n"
     ]
    }
   ],
   "source": [
    "# Check class distribution\n",
    "classes, counts = np.unique(y_train, return_counts=True)\n",
    "print(\"Class Distribution:\\n\", dict(zip(classes, counts)))\n",
    "\n",
    "if len(classes) > 1:\n",
    "    class_ratio = counts[1] / counts[0]\n",
    "    print(f\"\\nClass ratio: {class_ratio:.3f}\")\n",
    "else:\n",
    "    print(\"\\nOnly one class present.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf1687a-66bf-4c13-ae9d-b9f729255aae",
   "metadata": {},
   "source": [
    "### Introduce Noise to label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e605cc0-c7df-46fa-aafc-72d22d688dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert FLIP_LABEL_FRACTION > 0.0 and FLIP_LABEL_FRACTION < 1.0, \"FLIP_LABEL_FRACTION should be beween 0.0 and 1.0\"\n",
    "\n",
    "# Randomly select indices to flip\n",
    "if FLIP_LABEL_FRACTION > 0.0:\n",
    "    num_to_flip = int(FLIP_LABEL_FRACTION * len(y_train))\n",
    "    flip_indices = np.random.choice(len(y_train), size=num_to_flip, replace=False)\n",
    "\n",
    "    # If y_train is a pandas Series, convert to int for safe arithmetic\n",
    "    if hasattr(y_train, 'iloc'):\n",
    "        y_train = y_train.astype(int)\n",
    "        y_train.iloc[flip_indices] = 1 - y_train.iloc[flip_indices]\n",
    "    else:  # numpy array\n",
    "        y_train[flip_indices] = 1 - y_train[flip_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649caa02-af7b-4ed1-8893-ed4192ddc29d",
   "metadata": {},
   "source": [
    "### Make everything a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47910799-d5c6-4eb2-b8d2-fe5b597640b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values if hasattr(X_train, \"values\") else np.array(X_train)\n",
    "X_test = X_test.values if hasattr(X_test, \"values\") else np.array(X_test)\n",
    "\n",
    "y_train = y_train.values.ravel() if hasattr(y_train, \"values\") else np.array(y_train).ravel()\n",
    "y_test = y_test.values.ravel() if hasattr(y_test, \"values\") else np.array(y_test).ravel()\n",
    "\n",
    "y_embed_train = y_embed_train.values if hasattr(y_embed_train, \"values\") else np.array(y_embed_train)\n",
    "y_embed_test = y_embed_test.values if hasattr(y_embed_test, \"values\") else np.array(y_embed_test)\n",
    "\n",
    "assert(isinstance(X_train, np.ndarray))\n",
    "assert(isinstance(X_test, np.ndarray))\n",
    "assert(isinstance(y_train, np.ndarray))\n",
    "assert(isinstance(y_test, np.ndarray))\n",
    "assert(isinstance(y_embed_train, np.ndarray))\n",
    "assert(isinstance(y_embed_test, np.ndarray))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907be545",
   "metadata": {},
   "source": [
    "# **Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b23470a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from baseline_models import train_multitarget_baseline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3383a4b1",
   "metadata": {},
   "source": [
    "### Training Bayesian Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33a6ac8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " ######################################## GaussianNB Multitarget Regressor ########################################\n",
      "Train MSE per embedding: [1.68390992 1.58730418 1.54471279 1.41465405 1.74706266 1.67036554\n",
      " 2.33518277 4.37679504 4.94941253]\n",
      "Test MSE per embedding: [2.63151515 2.34060606 1.98060606 1.63030303 2.49939394 2.39393939\n",
      " 2.98787879 4.88727273 5.86424242]\n",
      "Average train MSE: 2.3677110530896432\n",
      "Average test MSE: 3.023973063973064\n"
     ]
    }
   ],
   "source": [
    "nb_model = GaussianNB()\n",
    "y_pred_nb, acc_nb = train_multitarget_baseline(\n",
    "                            model=nb_model,\n",
    "                            is_classifier=False,\n",
    "                            X_train=X_train,\n",
    "                            X_test=X_test,\n",
    "                            y_embed_train=y_embed_train,\n",
    "                            y_embed_test=y_embed_test,\n",
    "                            verbose=VERBOSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ac3cc7",
   "metadata": {},
   "source": [
    "### Training Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30e979e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter\n",
    "N_ESTIMATORS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dbaeae85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " ######################################## RandomForestRegressor Multitarget Regressor ########################################\n",
      "Train MSE per embedding: [0.04868177 0.04020042 0.06631898 0.05258557 0.05571394 0.04533048\n",
      " 0.04374636 0.0300101  0.01338597]\n",
      "Test MSE per embedding: [0.71028897 0.58013855 0.91118412 0.73295661 0.83929721 0.61563006\n",
      " 0.582684   0.37515891 0.17831927]\n",
      "Average train MSE: 0.043997066289527244\n",
      "Average test MSE: 0.6139619663299664\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestRegressor(n_estimators=N_ESTIMATORS, random_state=STATE, n_jobs=-1)\n",
    "y_pred_rf, mse_rf = train_multitarget_baseline(\n",
    "                                    model=rf_model, \n",
    "                                    is_classifier=False, \n",
    "                                    X_train=X_train, \n",
    "                                    X_test=X_test, \n",
    "                                    y_embed_train=y_embed_train, \n",
    "                                    y_embed_test=y_embed_test,\n",
    "                                    verbose=VERBOSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3172fa83",
   "metadata": {},
   "source": [
    "### Training Logistic Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f84084e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "MAX_ITERATIONS = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3635769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " ######################################## LogisticRegression Multitarget Classifier ########################################\n",
      "Train accuracy per embedding: [0.61684073 0.65943211 0.52529373 0.57865535 0.59252611 0.61471932\n",
      " 0.6316906  0.64295039 0.71230418]\n",
      "Test accuracy per embedding: [0.48363636 0.52727273 0.38545455 0.40727273 0.45212121 0.5430303\n",
      " 0.53212121 0.63757576 0.7369697 ]\n",
      "Average train accuracy: 0.6193791702930084\n",
      "Average test accuracy: 0.5228282828282829\n"
     ]
    }
   ],
   "source": [
    "log_model = LogisticRegression(max_iter=MAX_ITERATIONS, class_weight='balanced', random_state=STATE)\n",
    "y_pred_log, acc_log = train_multitarget_baseline(\n",
    "                            model=log_model,\n",
    "                            is_classifier=True,\n",
    "                            X_train=X_train,\n",
    "                            X_test=X_test,\n",
    "                            y_embed_train=y_embed_train,\n",
    "                            y_embed_test=y_embed_test,\n",
    "                            verbose=VERBOSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7acb7b-dd16-4725-96fe-5ba08b7a4259",
   "metadata": {},
   "source": [
    "## Proposed MLPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06a4020a-3be1-4625-9323-5a674670d6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from proposed_models import train_joint_model, train_split_model, train_deep_joint_model, train_deep_split_model\n",
    "\n",
    "DEVICE = \"cpu\"#torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "E_KEEP_RATE = 0.7\n",
    "l = 1\n",
    "if DATA == 'depression':\n",
    "    l = 1e-2\n",
    "elif DATA == 'insomnia':\n",
    "    l = 1e-2\n",
    "elif DATA == 'electrical_circuit':\n",
    "    l = 1\n",
    "\n",
    "EPOCHS = 100\n",
    "AUGMENT_EPOCHS = EPOCHS//2\n",
    "EARLY_STOP_EPOCHS = EPOCHS//5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a932baae-9847-409c-b512-8255f7be4e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using  cpu  for torch\n"
     ]
    }
   ],
   "source": [
    "# Sanity Checks\n",
    "print(\"Using \", DEVICE, \" for torch\")\n",
    "\n",
    "assert X_train.shape[0] >= 100 and y_train.shape[0] >= 100 and y_embed_train.shape[0] >= 100, \"Arrays must have at least 100 samples for the check.\"\n",
    "\n",
    "aligned = (len(X_train[:100]) == len(y_train[:100])) and (len(X_train[:100]) == len(y_embed_train[:100]))\n",
    "assert aligned, \"First 100 samples of X_train, y_train, and y_embed_train are not aligned.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777438b4",
   "metadata": {},
   "source": [
    "### Train Joint MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aebf6f8e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrain_joint_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_embed_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_embed_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m                    \u001b[49m\u001b[43me_kept_ratio\u001b[49m\u001b[43m=\u001b[49m\u001b[43mE_KEEP_RATE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m                    \u001b[49m\u001b[43ml\u001b[49m\u001b[43m=\u001b[49m\u001b[43ml\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m                    \u001b[49m\u001b[43maugment_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mAUGMENT_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mearly_stop_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEARLY_STOP_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDEVICE\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m                  \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaspe\\Documents\\Github_projects\\DSAIT4020-A2\\proposed_models.py:58\u001b[39m, in \u001b[36mtrain_joint_model\u001b[39m\u001b[34m(X_train, X_test, y_train, y_test, e_train, e_test, e_kept_ratio, l, epochs, augment_epochs, early_stop_epochs, device)\u001b[39m\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtrain_joint_model\u001b[39m( X_train, X_test, y_train, y_test, e_train, e_test, e_kept_ratio, l=\u001b[32m1.0\u001b[39m, epochs=\u001b[32m1000\u001b[39m, augment_epochs=\u001b[32m50\u001b[39m, early_stop_epochs=\u001b[32m20\u001b[39m, device=\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m ):\n\u001b[32m     57\u001b[39m \tdatasets, layer_sizes  = get_datasets_and_layer_sizes( X_train, X_test, y_train, y_test, e_train, e_test, e_kept_ratio )\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m \tmodel = \u001b[43mJointModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayer_sizes\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn_in\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayer_sizes\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn_reg\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml\u001b[49m\u001b[43m=\u001b[49m\u001b[43ml\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m \ttrain_proposal_model( datasets, model, title=\u001b[33m\"\u001b[39m\u001b[33mJoint\u001b[39m\u001b[33m\"\u001b[39m, epochs=epochs, augment_epochs=augment_epochs, early_stop_epochs=early_stop_epochs, device=device )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaspe\\Documents\\Github_projects\\DSAIT4020-A2\\shallow_models.py:13\u001b[39m, in \u001b[36mJointModel.__init__\u001b[39m\u001b[34m(self, n_features, hidden_size, l, device)\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m( \u001b[38;5;28mself\u001b[39m, n_features, hidden_size, l, device=\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m ):\n\u001b[32m     11\u001b[39m \t\u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m( n_features, hidden_size, device=device )\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \t\u001b[38;5;28mself\u001b[39m.optim = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptim\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAdam\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-3\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \t\u001b[38;5;28mself\u001b[39m.l = l\n\u001b[32m     15\u001b[39m \t\u001b[38;5;28mself\u001b[39m.to(device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaspe\\Documents\\Github_projects\\DSAIT4020-A2\\venv\\Lib\\site-packages\\torch\\optim\\adam.py:78\u001b[39m, in \u001b[36mAdam.__init__\u001b[39m\u001b[34m(self, params, lr, betas, eps, weight_decay, amsgrad, foreach, maximize, capturable, differentiable, fused)\u001b[39m\n\u001b[32m     64\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid weight_decay value: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mweight_decay\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     66\u001b[39m defaults = \u001b[38;5;28mdict\u001b[39m(\n\u001b[32m     67\u001b[39m     lr=lr,\n\u001b[32m     68\u001b[39m     betas=betas,\n\u001b[32m   (...)\u001b[39m\u001b[32m     76\u001b[39m     fused=fused,\n\u001b[32m     77\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefaults\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fused:\n\u001b[32m     81\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m differentiable:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaspe\\Documents\\Github_projects\\DSAIT4020-A2\\venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:371\u001b[39m, in \u001b[36mOptimizer.__init__\u001b[39m\u001b[34m(self, params, defaults)\u001b[39m\n\u001b[32m    368\u001b[39m     param_groups = [{\u001b[33m\"\u001b[39m\u001b[33mparams\u001b[39m\u001b[33m\"\u001b[39m: param_groups}]\n\u001b[32m    370\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m param_group \u001b[38;5;129;01min\u001b[39;00m param_groups:\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madd_param_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_group\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[38;5;66;03m# Allows _cuda_graph_capture_health_check to rig a poor man's TORCH_WARN_ONCE in python,\u001b[39;00m\n\u001b[32m    374\u001b[39m \u001b[38;5;66;03m# which I don't think exists\u001b[39;00m\n\u001b[32m    375\u001b[39m \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/issues/72948\u001b[39;00m\n\u001b[32m    376\u001b[39m \u001b[38;5;28mself\u001b[39m._warned_capturable_if_run_uncaptured = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaspe\\Documents\\Github_projects\\DSAIT4020-A2\\venv\\Lib\\site-packages\\torch\\_compile.py:27\u001b[39m, in \u001b[36m_disable_dynamo.<locals>.inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     25\u001b[39m disable_fn = \u001b[38;5;28mgetattr\u001b[39m(fn, \u001b[33m\"\u001b[39m\u001b[33m__dynamo_disable\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m disable_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\n\u001b[32m     29\u001b[39m     disable_fn = torch._dynamo.disable(fn, recursive)\n\u001b[32m     30\u001b[39m     fn.__dynamo_disable = disable_fn\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaspe\\Documents\\Github_projects\\DSAIT4020-A2\\venv\\Lib\\site-packages\\torch\\_dynamo\\__init__.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m convert_frame, eval_frame, resume_execution\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackends\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mregistry\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m list_backends, lookup_backend, register_backend\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcallback\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m callback_handler, on_compile_end, on_compile_start\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaspe\\Documents\\Github_projects\\DSAIT4020-A2\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:31\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_C\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mguards\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GlobalStateGuard\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributed\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_compile_pg\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CompileTimeInstructionCounter\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_guards\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compile_context, CompileContext, CompileId, tracing\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_logging\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m structured\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaspe\\Documents\\Github_projects\\DSAIT4020-A2\\venv\\Lib\\site-packages\\torch\\_dynamo\\utils.py:62\u001b[39m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_functorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_inductor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01minductor_config\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfx\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexperimental\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msymbolic_shapes\u001b[39;00m\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_pytree\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpytree\u001b[39;00m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m fx\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaspe\\Documents\\Github_projects\\DSAIT4020-A2\\venv\\Lib\\site-packages\\torch\\fx\\experimental\\symbolic_shapes.py:65\u001b[39m\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_guards\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ShapeGuard, Source, TracingContext\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_python_dispatch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_traceable_wrapper_subclass\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_sympy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     66\u001b[39m     Application, FloorDiv, Mod, PythonMod, IsNonOverlappingAndDenseIndicator, CleanDiv, FloorToInt, CeilToInt\n\u001b[32m     67\u001b[39m )\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_sympy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msolve\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m try_solve\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_sympy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnumbers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m int_oo\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaspe\\Documents\\Github_projects\\DSAIT4020-A2\\venv\\Lib\\site-packages\\torch\\utils\\_sympy\\functions.py:7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01moperator\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msympy\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msympy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m S\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msympy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m sympify\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaspe\\Documents\\Github_projects\\DSAIT4020-A2\\venv\\Lib\\site-packages\\sympy\\__init__.py:108\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01massumptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (AppliedPredicate, Predicate, AssumptionsContext,\n\u001b[32m     72\u001b[39m         assuming, Q, ask, register_handler, remove_handler, refine)\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpolys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (Poly, PurePoly, poly_from_expr, parallel_poly_from_expr,\n\u001b[32m     75\u001b[39m         degree, total_degree, degree_list, LC, LM, LT, pdiv, prem, pquo,\n\u001b[32m     76\u001b[39m         pexquo, div, rem, quo, exquo, half_gcdex, gcdex, invert,\n\u001b[32m   (...)\u001b[39m\u001b[32m    105\u001b[39m         legendre_poly, laguerre_poly, apart, apart_list, assemble_partfrac_list,\n\u001b[32m    106\u001b[39m         Options, ring, xring, vring, sring, field, xfield, vfield, sfield)\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mseries\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (Order, O, limit, Limit, gruntz, series, approximants,\n\u001b[32m    109\u001b[39m         residue, EmptySequence, SeqPer, SeqFormula, sequence, SeqAdd, SeqMul,\n\u001b[32m    110\u001b[39m         fourier_series, fps, difference_delta, limit_seq)\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (factorial, factorial2, rf, ff, binomial,\n\u001b[32m    113\u001b[39m         RisingFactorial, FallingFactorial, subfactorial, carmichael,\n\u001b[32m    114\u001b[39m         fibonacci, lucas, motzkin, tribonacci, harmonic, bernoulli, bell, euler,\n\u001b[32m   (...)\u001b[39m\u001b[32m    135\u001b[39m         Znm, elliptic_k, elliptic_f, elliptic_e, elliptic_pi, beta, mathieus,\n\u001b[32m    136\u001b[39m         mathieuc, mathieusprime, mathieucprime, riemann_xi, betainc, betainc_regularized)\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mntheory\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (nextprime, prevprime, prime, primerange,\n\u001b[32m    139\u001b[39m         randprime, Sieve, sieve, primorial, cycle_length, composite,\n\u001b[32m    140\u001b[39m         compositepi, isprime, divisors, proper_divisors, factorint,\n\u001b[32m   (...)\u001b[39m\u001b[32m    151\u001b[39m         continued_fraction_iterator, continued_fraction_reduce,\n\u001b[32m    152\u001b[39m         continued_fraction_convergents, continued_fraction, egyptian_fraction)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaspe\\Documents\\Github_projects\\DSAIT4020-A2\\venv\\Lib\\site-packages\\sympy\\series\\__init__.py:12\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfourier\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m fourier_series\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mformal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m fps\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlimitseq\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m difference_delta, limit_seq\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msympy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msingleton\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m S\n\u001b[32m     15\u001b[39m EmptySequence = S.EmptySequence\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1360\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1331\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:935\u001b[39m, in \u001b[36m_load_unlocked\u001b[39m\u001b[34m(spec)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:995\u001b[39m, in \u001b[36mexec_module\u001b[39m\u001b[34m(self, module)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1091\u001b[39m, in \u001b[36mget_code\u001b[39m\u001b[34m(self, fullname)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1190\u001b[39m, in \u001b[36mget_data\u001b[39m\u001b[34m(self, path)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "train_joint_model( X_train, X_test, y_train, y_test, y_embed_train, y_embed_test,\n",
    "                    e_kept_ratio=E_KEEP_RATE,\n",
    "                    l=l,\n",
    "                    epochs=EPOCHS,\n",
    "                    augment_epochs=AUGMENT_EPOCHS,\n",
    "                    early_stop_epochs=EARLY_STOP_EPOCHS,\n",
    "                    device=DEVICE\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3fbefb",
   "metadata": {},
   "source": [
    "### Train Split MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da297fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\t###################################---------------\t[70.0% - DONE]\n",
      "\n",
      "================================================================================\n",
      "================================   Split MLP   ================================\n",
      "================================================================================\n",
      "Regression Results:\n",
      "MSE:\t0.9559118747711182\n",
      "\n",
      "\n",
      "Classification Results:\n",
      "F1 score: 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96       775\n",
      "           1       0.00      0.00      0.00        59\n",
      "\n",
      "    accuracy                           0.93       834\n",
      "   macro avg       0.46      0.50      0.48       834\n",
      "weighted avg       0.86      0.93      0.90       834\n",
      "\n",
      "Confusion matrix:\n",
      " [[775   0]\n",
      " [ 59   0]]\n",
      "Training:\t###-----------------------------------------------\t[6.0%]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.14/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/usr/lib/python3.14/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/usr/lib/python3.14/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\t##################################################\t[100.0%]\n",
      "\n",
      "================================================================================\n",
      "==========================   Split MLP (Augmented)   ==========================\n",
      "================================================================================\n",
      "Regression Results:\n",
      "MSE:\t0.9751307964324951\n",
      "\n",
      "\n",
      "Classification Results:\n",
      "F1 score: 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96       775\n",
      "           1       0.00      0.00      0.00        59\n",
      "\n",
      "    accuracy                           0.93       834\n",
      "   macro avg       0.46      0.50      0.48       834\n",
      "weighted avg       0.86      0.93      0.90       834\n",
      "\n",
      "Confusion matrix:\n",
      " [[775   0]\n",
      " [ 59   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.14/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/usr/lib/python3.14/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/usr/lib/python3.14/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "train_split_model( X_train, X_test, y_train, y_test, y_embed_train, y_embed_test,\n",
    "                    e_kept_ratio=E_KEEP_RATE,\n",
    "                    epochs=EPOCHS,\n",
    "                    augment_epochs=AUGMENT_EPOCHS,\n",
    "                    early_stop_epochs=EARLY_STOP_EPOCHS,\n",
    "                    device=DEVICE\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31cd9f3-7021-4891-8cad-f2e4a9385bc1",
   "metadata": {},
   "source": [
    "### Train Deep Joint Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d3f100-ec35-4495-9dbf-a8fa10722067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\t############--------------------------------------\t[25.0% - DONE]\n",
      "\n",
      "================================================================================\n",
      "==============================   Deep Joint MLP   ==============================\n",
      "================================================================================\n",
      "Regression Results:\n",
      "MSE:\t1.1690424680709839\n",
      "\n",
      "\n",
      "Classification Results:\n",
      "F1 score: 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96       775\n",
      "           1       0.00      0.00      0.00        59\n",
      "\n",
      "    accuracy                           0.93       834\n",
      "   macro avg       0.46      0.50      0.48       834\n",
      "weighted avg       0.86      0.93      0.90       834\n",
      "\n",
      "Confusion matrix:\n",
      " [[775   0]\n",
      " [ 59   0]]\n",
      "Training:\t###-----------------------------------------------\t[6.0%]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.14/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/usr/lib/python3.14/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/usr/lib/python3.14/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\t####################------------------------------\t[40.0% - DONE]\n",
      "\n",
      "================================================================================\n",
      "========================   Deep Joint MLP (Augmented)   ========================\n",
      "================================================================================\n",
      "Regression Results:\n",
      "MSE:\t1.1690424680709839\n",
      "\n",
      "\n",
      "Classification Results:\n",
      "F1 score: 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96       775\n",
      "           1       0.00      0.00      0.00        59\n",
      "\n",
      "    accuracy                           0.93       834\n",
      "   macro avg       0.46      0.50      0.48       834\n",
      "weighted avg       0.86      0.93      0.90       834\n",
      "\n",
      "Confusion matrix:\n",
      " [[775   0]\n",
      " [ 59   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.14/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/usr/lib/python3.14/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/usr/lib/python3.14/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "train_deep_joint_model( X_train, X_test, y_train, y_test, y_embed_train, y_embed_test,\n",
    "                        e_kept_ratio=E_KEEP_RATE,\n",
    "                        l=l,\n",
    "                        epochs=EPOCHS,\n",
    "                        augment_epochs=AUGMENT_EPOCHS,\n",
    "                        early_stop_epochs=EARLY_STOP_EPOCHS,\n",
    "                        device=DEVICE\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eae81c0-f941-48f9-9ee6-ab0b9837fdb8",
   "metadata": {},
   "source": [
    "### Train Deep Split Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9afe671-bc85-474e-a353-870b65329c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\t######################################------------\t[77.0% - DONE]\n",
      "\n",
      "================================================================================\n",
      "==============================   Deep Split MLP   ==============================\n",
      "================================================================================\n",
      "Regression Results:\n",
      "MSE:\t1.2037678956985474\n",
      "\n",
      "\n",
      "Classification Results:\n",
      "F1 score: 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96       775\n",
      "           1       0.00      0.00      0.00        59\n",
      "\n",
      "    accuracy                           0.93       834\n",
      "   macro avg       0.46      0.50      0.48       834\n",
      "weighted avg       0.86      0.93      0.90       834\n",
      "\n",
      "Confusion matrix:\n",
      " [[775   0]\n",
      " [ 59   0]]\n",
      "Training:\t#####---------------------------------------------\t[10.0%]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.14/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/usr/lib/python3.14/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/usr/lib/python3.14/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\t##################################################\t[100.0%]\n",
      "\n",
      "================================================================================\n",
      "========================   Deep Split MLP (Augmented)   ========================\n",
      "================================================================================\n",
      "Regression Results:\n",
      "MSE:\t1.2037678956985474\n",
      "\n",
      "\n",
      "Classification Results:\n",
      "F1 score: 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96       775\n",
      "           1       0.00      0.00      0.00        59\n",
      "\n",
      "    accuracy                           0.93       834\n",
      "   macro avg       0.46      0.50      0.48       834\n",
      "weighted avg       0.86      0.93      0.90       834\n",
      "\n",
      "Confusion matrix:\n",
      " [[775   0]\n",
      " [ 59   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.14/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/usr/lib/python3.14/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/usr/lib/python3.14/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "train_deep_split_model( X_train, X_test, y_train, y_test, y_embed_train, y_embed_test,\n",
    "                        e_kept_ratio=E_KEEP_RATE,\n",
    "                        epochs=EPOCHS,\n",
    "                        augment_epochs=AUGMENT_EPOCHS,\n",
    "                        early_stop_epochs=EARLY_STOP_EPOCHS,\n",
    "                        device=DEVICE\n",
    "                      )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
